{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "%pylab inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from keras.models import Model\n",
    "import keras.backend as K\n",
    "from keras.layers import Input, Dense, Conv2D, Add, Activation\n",
    "\n",
    "from keras.datasets import mnist, cifar10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model specifications"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MaskedConv2D(Conv2D):\n",
    "    \"\"\"\n",
    "    Masked Convolution from [1]. Contains the same implementation of Conv2D from keras, but\n",
    "    allows one to specify whether the mask type is 'A', 'B', or None.\n",
    "    \n",
    "    Params\n",
    "    ------\n",
    "    \n",
    "    mask_type: string, default=None\n",
    "        Determines the masking type for the convolution from [1].\n",
    "    \n",
    "    References\n",
    "    ----------\n",
    "    \n",
    "    [1] https://arxiv.org/pdf/1601.06759.pdf\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, filters, kernel_size, padding='same', mask_type=None, **kwargs):\n",
    "        super(MaskedConv2D, self).__init__(filters, kernel_size, padding=padding, **kwargs)\n",
    "        self.mask_type = mask_type\n",
    "        \n",
    "    def build(self, input_shape):\n",
    "        super(MaskedConv2D, self).build(input_shape)\n",
    "        \n",
    "        if self.data_format == 'channels_first':\n",
    "            channel_axis = 1\n",
    "        else:\n",
    "            channel_axis = -1\n",
    "        if input_shape[channel_axis] is None:\n",
    "            raise ValueError('The channel dimension of the inputs '\n",
    "                             'should be defined. Found `None`.')\n",
    "        input_dim = input_shape[channel_axis]\n",
    "        kernel_shape = self.kernel_size + (input_dim, self.filters)\n",
    "        \n",
    "        # assert that the kernel size is odd\n",
    "        assert self.kernel_size[0] % 2 == 1\n",
    "        assert self.kernel_size[1] % 2 == 1\n",
    "        \n",
    "        center = (self.kernel_size[0] // 2, self.kernel_size[1] // 2)\n",
    "        self.mask = np.ones(kernel_shape)\n",
    "        \n",
    "        # mask out values right of center\n",
    "        self.mask[center[0]:, center[1]+1:, :, :] = 0\n",
    "        \n",
    "        # mask out values below center\n",
    "        self.mask[center[0]+1:, :, :, :] = 0\n",
    "        \n",
    "        # mask out center if masking type is 'A'\n",
    "        if self.mask_type == 'A':\n",
    "            self.mask[center[0], center[0], :, :] = 0\n",
    "        \n",
    "        # mask RGB channels\n",
    "        \n",
    "        self.mask = K.variable(self.mask)\n",
    "        \n",
    "    def call(self, inputs):\n",
    "        if self.mask_type is None:\n",
    "            return super(MaskedConv2D, self).call(inputs)\n",
    "        outputs = K.conv2d(\n",
    "            inputs,\n",
    "            self.kernel * self.mask,\n",
    "            strides=self.strides,\n",
    "            padding=self.padding,\n",
    "            data_format=self.data_format,\n",
    "            dilation_rate=self.dilation_rate\n",
    "        )\n",
    "        if self.use_bias:\n",
    "            outputs = K.bias_add(\n",
    "            outputs,\n",
    "            self.bias,\n",
    "            data_format=self.data_format\n",
    "            )\n",
    "        if self.activation is not None:\n",
    "            return self.activation(outputs)\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResidualBlock(object):\n",
    "    \n",
    "    def __init__(self, filters):\n",
    "        self.filters = filters\n",
    "        \n",
    "    def __call__(self, model):\n",
    "        block = Activation('relu')(model)\n",
    "        block = Conv2D(self.filters // 2, 1, activation='relu')(block)\n",
    "        block = MaskedConv2D(self.filters // 2, 3, mask_type='B', activation='relu')(block)\n",
    "        block = Conv2D(self.filters, 1)(block)\n",
    "        \n",
    "        return Add()([model, block])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_14 (InputLayer)           (None, 28, 28, 1)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "masked_conv2d_18 (MaskedConv2D) (None, 28, 28, 128)  6400        input_14[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_10 (Activation)      (None, 28, 28, 128)  0           masked_conv2d_18[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_19 (Conv2D)              (None, 28, 28, 64)   8256        activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "masked_conv2d_19 (MaskedConv2D) (None, 28, 28, 64)   36928       conv2d_19[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_20 (Conv2D)              (None, 28, 28, 128)  8320        masked_conv2d_19[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "add_7 (Add)                     (None, 28, 28, 128)  0           masked_conv2d_18[0][0]           \n",
      "                                                                 conv2d_20[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_11 (Activation)      (None, 28, 28, 128)  0           add_7[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_21 (Conv2D)              (None, 28, 28, 1)    129         activation_11[0][0]              \n",
      "==================================================================================================\n",
      "Total params: 60,033\n",
      "Trainable params: 60,033\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "x = Input(shape=(28, 28, 1))\n",
    "y = MaskedConv2D(128, 7, mask_type='A')(x)\n",
    "y = ResidualBlock(128)(y)\n",
    "y = Activation('relu')(y)\n",
    "y = Conv2D(1, 1, activation='sigmoid')(y)\n",
    "model = Model(x, y)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "x_train = np.expand_dims(x_train, -1)\n",
    "x_test = np.expand_dims(x_test, -1)\n",
    "x_train = x_train/255.\n",
    "x_test = x_test/255."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "60000/60000 [==============================] - 116s 2ms/step - loss: 0.2819\n",
      "Epoch 2/10\n",
      "60000/60000 [==============================] - 203s 3ms/step - loss: 0.0950\n",
      "Epoch 3/10\n",
      "60000/60000 [==============================] - 273s 5ms/step - loss: 0.0889\n",
      "Epoch 4/10\n",
      "60000/60000 [==============================] - 322s 5ms/step - loss: 0.0864\n",
      "Epoch 5/10\n",
      "60000/60000 [==============================] - 322s 5ms/step - loss: 0.0849\n",
      "Epoch 6/10\n",
      "60000/60000 [==============================] - 250s 4ms/step - loss: 0.0840\n",
      "Epoch 7/10\n",
      "60000/60000 [==============================] - 278s 5ms/step - loss: 0.0834\n",
      "Epoch 8/10\n",
      "40000/60000 [===================>..........] - ETA: 1:37 - loss: 0.0830"
     ]
    }
   ],
   "source": [
    "def pixel_cnn_loss(y_true, y_pred):\n",
    "    return K.sum(K.binary_crossentropy(y_true, y_pred), axis=(-1, -2, -3))\n",
    "\n",
    "model.compile(loss=pixel_cnn_loss, optimizer='adam')\n",
    "model.fit(x_train, x_train, batch_size=1000, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tensorflow-gpu]",
   "language": "python",
   "name": "conda-env-tensorflow-gpu-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
