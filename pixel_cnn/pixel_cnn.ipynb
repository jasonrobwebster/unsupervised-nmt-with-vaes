{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "%pylab inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from keras.models import Model\n",
    "import keras.backend as K\n",
    "from keras.layers import Input, Dense, Conv2D, Add, Activation\n",
    "\n",
    "from keras.datasets import mnist, cifar10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def obtain(dir_path):\n",
    "    \"\"\"\n",
    "    Downloads the dataset to ``dir_path``.\n",
    "    \"\"\"\n",
    "\n",
    "    dir_path = os.path.expanduser(dir_path)\n",
    "    print('Downloading the dataset')\n",
    "    import urllib\n",
    "    urllib.urlretrieve('http://www.cs.toronto.edu/~larocheh/public/datasets/binarized_mnist/binarized_mnist_train.amat',os.path.join(dir_path,'binarized_mnist_train.amat'))\n",
    "    urllib.urlretrieve('http://www.cs.toronto.edu/~larocheh/public/datasets/binarized_mnist/binarized_mnist_valid.amat',os.path.join(dir_path,'binarized_mnist_valid.amat'))\n",
    "    urllib.urlretrieve('http://www.cs.toronto.edu/~larocheh/public/datasets/binarized_mnist/binarized_mnist_test.amat',os.path.join(dir_path,'binarized_mnist_test.amat'))\n",
    "\n",
    "    print('Done                     ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model specifications"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MaskedConv2D(Conv2D):\n",
    "    \"\"\"\n",
    "    Masked Convolution from [1]. Contains the same implementation of Conv2D from keras, but\n",
    "    allows one to specify whether the mask type is 'A', 'B', or None.\n",
    "    \n",
    "    Params\n",
    "    ------\n",
    "    \n",
    "    mask_type: string, default=None\n",
    "        Determines the masking type for the convolution from [1].\n",
    "    \n",
    "    References\n",
    "    ----------\n",
    "    \n",
    "    [1] https://arxiv.org/pdf/1601.06759.pdf\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, filters, kernel_size, padding='same', mask_type=None, **kwargs):\n",
    "        super(MaskedConv2D, self).__init__(filters, kernel_size, padding=padding, **kwargs)\n",
    "        self.mask_type = mask_type\n",
    "        \n",
    "    def build(self, input_shape):\n",
    "        super(MaskedConv2D, self).build(input_shape)\n",
    "        \n",
    "        if self.data_format == 'channels_first':\n",
    "            channel_axis = 1\n",
    "        else:\n",
    "            channel_axis = -1\n",
    "        if input_shape[channel_axis] is None:\n",
    "            raise ValueError('The channel dimension of the inputs '\n",
    "                             'should be defined. Found `None`.')\n",
    "        input_dim = input_shape[channel_axis]\n",
    "        kernel_shape = self.kernel_size + (input_dim, self.filters)\n",
    "        \n",
    "        # assert that the kernel size is odd\n",
    "        assert self.kernel_size[0] % 2 == 1\n",
    "        assert self.kernel_size[1] % 2 == 1\n",
    "        \n",
    "        center = (self.kernel_size[0] // 2, self.kernel_size[1] // 2)\n",
    "        self.mask = np.ones(kernel_shape)\n",
    "        \n",
    "        # mask out values right of center\n",
    "        self.mask[center[0]:, center[1]+1:, :, :] = 0\n",
    "        \n",
    "        # mask out values below center\n",
    "        self.mask[center[0]+1:, :, :, :] = 0\n",
    "        \n",
    "        # mask out center if masking type is 'A'\n",
    "        if self.mask_type == 'A':\n",
    "            self.mask[center[0], center[0], :, :] = 0\n",
    "        \n",
    "        # mask RGB channels\n",
    "        \n",
    "        self.mask = K.variable(self.mask)\n",
    "        \n",
    "    def call(self, inputs):\n",
    "        if self.mask_type is None:\n",
    "            return super(MaskedConv2D, self).call(inputs)\n",
    "        outputs = K.conv2d(\n",
    "            inputs,\n",
    "            self.kernel * self.mask,\n",
    "            strides=self.strides,\n",
    "            padding=self.padding,\n",
    "            data_format=self.data_format,\n",
    "            dilation_rate=self.dilation_rate\n",
    "        )\n",
    "        if self.use_bias:\n",
    "            outputs = K.bias_add(\n",
    "            outputs,\n",
    "            self.bias,\n",
    "            data_format=self.data_format\n",
    "            )\n",
    "        if self.activation is not None:\n",
    "            return self.activation(outputs)\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResidualBlock(object):\n",
    "    \n",
    "    def __init__(self, filters):\n",
    "        self.filters = filters\n",
    "        \n",
    "    def __call__(self, model):\n",
    "        block = Activation('relu')(model)\n",
    "        block = Conv2D(self.filters // 2, 1, activation='relu')(block)\n",
    "        block = MaskedConv2D(self.filters // 2, 3, mask_type='B', activation='relu')(block)\n",
    "        block = Conv2D(self.filters, 1)(block)\n",
    "        \n",
    "        return Add()([model, block])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "x_train = np.expand_dims(x_train, -1)\n",
    "x_test = np.expand_dims(x_test, -1)\n",
    "x_train = x_train/255.\n",
    "x_test = x_test/255.\n",
    "\n",
    "x_train = (x_train > np.random.rand(*x_train.shape)).astype(np.int32)\n",
    "x_test = (x_test > np.random.rand(*x_test.shape)).astype(np.int32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_14 (InputLayer)           (None, 28, 28, 1)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "masked_conv2d_18 (MaskedConv2D) (None, 28, 28, 128)  6400        input_14[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_10 (Activation)      (None, 28, 28, 128)  0           masked_conv2d_18[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_19 (Conv2D)              (None, 28, 28, 64)   8256        activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "masked_conv2d_19 (MaskedConv2D) (None, 28, 28, 64)   36928       conv2d_19[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_20 (Conv2D)              (None, 28, 28, 128)  8320        masked_conv2d_19[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "add_7 (Add)                     (None, 28, 28, 128)  0           masked_conv2d_18[0][0]           \n",
      "                                                                 conv2d_20[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_11 (Activation)      (None, 28, 28, 128)  0           add_7[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_21 (Conv2D)              (None, 28, 28, 1)    129         activation_11[0][0]              \n",
      "==================================================================================================\n",
      "Total params: 60,033\n",
      "Trainable params: 60,033\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "x = Input(shape=(28, 28, 1))\n",
    "y = MaskedConv2D(128, 7, mask_type='A')(x)\n",
    "y = ResidualBlock(128)(y)\n",
    "y = Activation('relu')(y)\n",
    "y = Conv2D(1, 1, activation='sigmoid')(y)\n",
    "model = Model(x, y)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "60000/60000 [==============================] - 133s 2ms/step - loss: 107.8308\n",
      "Epoch 2/10\n",
      "60000/60000 [==============================] - 212s 4ms/step - loss: 100.7603\n",
      "Epoch 3/10\n",
      "60000/60000 [==============================] - 322s 5ms/step - loss: 99.6640\n",
      "Epoch 4/10\n",
      "60000/60000 [==============================] - 321s 5ms/step - loss: 99.0552\n",
      "Epoch 5/10\n",
      "60000/60000 [==============================] - 256s 4ms/step - loss: 98.6632\n",
      "Epoch 6/10\n",
      "60000/60000 [==============================] - 139s 2ms/step - loss: 98.4053\n",
      "Epoch 7/10\n",
      "60000/60000 [==============================] - 155s 3ms/step - loss: 98.2346\n",
      "Epoch 8/10\n",
      "23000/60000 [==========>...................] - ETA: 1:35 - loss: 97.8249"
     ]
    }
   ],
   "source": [
    "def pixel_cnn_loss(y_true, y_pred):\n",
    "    return K.sum(K.binary_crossentropy(y_true, y_pred), axis=(-1, -2, -3))\n",
    "\n",
    "model.compile(loss=pixel_cnn_loss, optimizer='adam')\n",
    "model.fit(x_train, x_train, batch_size=1000, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1d82bb0aeb8>"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "x_half = x_train[:100]\n",
    "x_half[:, 14:] = 0\n",
    "imshow(x_half[0][:, :, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_pred = x_half\n",
    "for i in range(14, 28):\n",
    "    for j in range(0, 28):\n",
    "        pred = model.predict(x_pred)\n",
    "        x_pred[:, i, j] = pred[:, i, j] > np.random.rand(*pred.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1d82bd2c2e8>"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "imshow(x_pred[4][:, :, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tensorflow-gpu]",
   "language": "python",
   "name": "conda-env-tensorflow-gpu-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
